{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import ffmpeg\n",
    "import os \n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "import asyncio\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract audio from video\n",
    "def extract_audio(video_path, output_audio_path):\n",
    "    print('Extracting audio from video...')\n",
    "    ffmpeg.input(video_path).output(output_audio_path).run()\n",
    "    print('Audio extracted successfully!')\n",
    "    return output_audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert audio file to text\n",
    "\n",
    "# create a speech recognition object\n",
    "r = sr.Recognizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe the audio file to text\n",
    "def transcribe_audio(path):\n",
    "    \"\"\" a function to recognize speech in the audio file, so that we don't repeat ourselves in in other functions \"\"\"\n",
    "    # use the audio file as the audio source\n",
    "    with sr.AudioFile(path) as source:\n",
    "        audio_listened = r.record(source)\n",
    "        # try converting it to text\n",
    "        text = r.recognize_google(audio_listened)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "# Translator method for translation\n",
    "translator = Translator()\n",
    "\n",
    "# Source and target languages\n",
    "from_lang = 'hi'\n",
    "to_lang = 'en'\n",
    "\n",
    "# Translate the text\n",
    "async def translate_text(source_text):\n",
    "    async with Translator() as translator:\n",
    "        result = await translator.translate(source_text, src=from_lang, dest=to_lang)\n",
    "        return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that splits the audio file into chunks on silence and applies speech recognition\n",
    "def get_large_audio_transcription_on_silence(path):\n",
    "    print('Converting audio to text...')\n",
    "    \n",
    "    \"\"\"Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_file(path)  \n",
    "    # split audio sound where silence is 500 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-10,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio_chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        try:\n",
    "            text = transcribe_audio(chunk_filename)\n",
    "        except sr.UnknownValueError as e:\n",
    "            print(\"Error:\", str(e))\n",
    "        else:\n",
    "            text = f\"{text.capitalize()}. \"\n",
    "            print(chunk_filename, \":\", text)\n",
    "            translated_text = asyncio.run(translate_text(text))\n",
    "            whole_text += translated_text\n",
    "    print('Text generated successfully! \\n')\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting audio from video...\n",
      "Audio extracted successfully!\n",
      "Converting audio to text...\n",
      "audio_chunks\\chunk1.wav : Suchi ki koi machine hai jo aapke hisab se aapki almari set kar de ya aapke parivar ke har member ko unki pasand ke hisab se coffee sar kar de basically aapka har din aasan banaa. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\All_Code_Files\\AI Codes\\INFOSYS_STSS_APP\\stss_app_env\\Lib\\site-packages\\pygments\\regexopt.py:39: RuntimeWarning: coroutine 'translate_text' was never awaited\n",
      "  return open_paren + regex_opt_inner(strings[1:], '(?:') \\\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m outputFileName = extract_audio(inputPath, outputPath)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Step 2\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m generated_text = \u001b[43mget_large_audio_transcription_on_silence\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputFileName\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(generated_text)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mget_large_audio_transcription_on_silence\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     35\u001b[39m         text = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext.capitalize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     36\u001b[39m         \u001b[38;5;28mprint\u001b[39m(chunk_filename, \u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m, text)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m         translated_text = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranslate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m         whole_text += translated_text\n\u001b[32m     39\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mText generated successfully! \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\python-3.11.3(64-bit)\\Lib\\asyncio\\runners.py:186\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "# Run the app\n",
    "# Step 1\n",
    "fileName = 'video'\n",
    "inputPath = './' + fileName + '.mp4'\n",
    "outputPath = './' + fileName + '.mp3'\n",
    "\n",
    "outputFileName = extract_audio(inputPath, outputPath)\n",
    "\n",
    "# Step 2\n",
    "generated_text = get_large_audio_transcription_on_silence(outputFileName)\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stss_app_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
